{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f219a2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\plantdisease\" (use force=True to force download)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets --quiet\n",
    "import opendatasets as od\n",
    "od.download('https://www.kaggle.com/datasets/emmarex/plantdisease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9eea67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19824c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b63f0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 20638\n"
     ]
    }
   ],
   "source": [
    "root_path = 'plantdisease/PlantVillage/'\n",
    "img_path = []\n",
    "labels_path = []\n",
    "\n",
    "for label in os.listdir(root_path):\n",
    "    for item in os.listdir(f'{root_path}/{label}'):\n",
    "        img_path.append(f'{root_path}/{label}/{item}')\n",
    "        labels_path.append(label)\n",
    "        \n",
    "print(f'Number of Images: {len(img_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0abad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Tomato__Tomato_YellowLeaf__Curl_Virus          3208\n",
      "Tomato_Bacterial_spot                          2127\n",
      "Tomato_Late_blight                             1909\n",
      "Tomato_Septoria_leaf_spot                      1771\n",
      "Tomato_Spider_mites_Two_spotted_spider_mite    1676\n",
      "Tomato_healthy                                 1591\n",
      "Pepper__bell___healthy                         1478\n",
      "Tomato__Target_Spot                            1404\n",
      "Potato___Early_blight                          1000\n",
      "Potato___Late_blight                           1000\n",
      "Tomato_Early_blight                            1000\n",
      "Pepper__bell___Bacterial_spot                   997\n",
      "Tomato_Leaf_Mold                                952\n",
      "Tomato__Tomato_mosaic_virus                     373\n",
      "Potato___healthy                                152\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path   \n",
       "0  plantdisease/PlantVillage//Pepper__bell___Bact...  \\\n",
       "1  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "2  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "3  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "4  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "\n",
       "                           label  \n",
       "0  Pepper__bell___Bacterial_spot  \n",
       "1  Pepper__bell___Bacterial_spot  \n",
       "2  Pepper__bell___Bacterial_spot  \n",
       "3  Pepper__bell___Bacterial_spot  \n",
       "4  Pepper__bell___Bacterial_spot  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of our Dataframe\n",
    "data_df = pd.DataFrame(zip(img_path, labels_path), columns = ['image_path', 'label'])\n",
    "\n",
    "# Print the distribution of data among classes and the format of our DataFrame.\n",
    "print(data_df['label'].value_counts())\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4cd21e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16510, Validation size: 2064, Test size: 2064\n"
     ]
    }
   ],
   "source": [
    "train = data_df.sample(frac=0.8)\n",
    "val = data_df.drop(train.index)\n",
    "test = val.sample(frac=0.5)\n",
    "val = val.drop(test.index)\n",
    "\n",
    "print(f'Train size: {len(train)}, Validation size: {len(val)}, Test size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78d692c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder for the Labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_df['label'])\n",
    "\n",
    "# Create a transform for transforming the images in the same - appropriate form\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(dtype=torch.float)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88e8a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantsDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.labels = torch.tensor(label_encoder.transform(dataframe['label']), dtype=torch.long).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        image = Image.open(self.dataframe.iloc[indx, 0]).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image).to(device)\n",
    "        \n",
    "        label = self.labels[indx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e17d6971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.7804, 0.7882, 0.7373,  ..., 0.6824, 0.6078, 0.6980],\n",
      "         [0.7216, 0.7412, 0.7451,  ..., 0.7529, 0.6824, 0.6706],\n",
      "         [0.7216, 0.7255, 0.7608,  ..., 0.6627, 0.6392, 0.5725],\n",
      "         ...,\n",
      "         [0.4706, 0.4627, 0.4706,  ..., 0.5020, 0.5098, 0.4824],\n",
      "         [0.4235, 0.4471, 0.4627,  ..., 0.4706, 0.4706, 0.4510],\n",
      "         [0.3569, 0.4118, 0.4471,  ..., 0.4392, 0.5255, 0.4275]],\n",
      "\n",
      "        [[0.7412, 0.7490, 0.6980,  ..., 0.6588, 0.5843, 0.6745],\n",
      "         [0.6824, 0.7020, 0.7059,  ..., 0.7294, 0.6588, 0.6471],\n",
      "         [0.6824, 0.6863, 0.7216,  ..., 0.6392, 0.6157, 0.5490],\n",
      "         ...,\n",
      "         [0.4157, 0.4078, 0.4157,  ..., 0.4471, 0.4549, 0.4275],\n",
      "         [0.3686, 0.3922, 0.4078,  ..., 0.4157, 0.4157, 0.3961],\n",
      "         [0.3020, 0.3569, 0.3922,  ..., 0.3843, 0.4706, 0.3725]],\n",
      "\n",
      "        [[0.7451, 0.7529, 0.7020,  ..., 0.6667, 0.5922, 0.6824],\n",
      "         [0.6863, 0.7059, 0.7098,  ..., 0.7373, 0.6667, 0.6549],\n",
      "         [0.6863, 0.6902, 0.7255,  ..., 0.6471, 0.6235, 0.5569],\n",
      "         ...,\n",
      "         [0.4118, 0.4039, 0.4118,  ..., 0.4471, 0.4549, 0.4275],\n",
      "         [0.3647, 0.3882, 0.4039,  ..., 0.4157, 0.4157, 0.3961],\n",
      "         [0.2980, 0.3529, 0.3882,  ..., 0.3843, 0.4706, 0.3725]]]), tensor(10))\n"
     ]
    }
   ],
   "source": [
    "train_data = PlantsDataset(train, transform=transform)\n",
    "val_data = PlantsDataset(val, transform=transform)\n",
    "test_data = PlantsDataset(test, transform=transform)\n",
    "\n",
    "print(val_data.__getitem__(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82fc1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate = 1e-3\n",
    "Batch_Size = 16\n",
    "Epochs = 1000\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=Batch_Size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=Batch_Size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e2fc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "class Plants(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv2d1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2d2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv2d3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv2d4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Maxpooling\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Activation Function\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "        # Flatten Layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Dense Layers\n",
    "        self.dense1 = nn.Linear((128*16*16), 256)\n",
    "        self.dense2 = nn.Linear(256, 128)\n",
    "        self.dense3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, number_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "                                    # x = (3, 256, 256)\n",
    "        # Stage 1\n",
    "        x = self.conv2d1(x)        # (16, 256, 256)\n",
    "        x = self.maxpooling(x)     # (16, 128, 128)\n",
    "        x = self.activation(x)     # (16, 128, 128)\n",
    "        \n",
    "        # Stage 2\n",
    "        x = self.conv2d2(x)        # (32, 128, 128)\n",
    "        x = self.maxpooling(x)     # (32, 64, 64)\n",
    "        x = self.activation(x)     # (32, 64, 64)\n",
    "    \n",
    "        # Stage 3\n",
    "        x = self.conv2d3(x)        # (64, 64, 64)\n",
    "        x = self.maxpooling(x)     # (64, 32, 32)\n",
    "        x = self.activation(x)     # (64, 32, 32)\n",
    "\n",
    "        # Stage 4\n",
    "        x = self.conv2d4(x)        # (128, 32, 32)\n",
    "        x = self.maxpooling(x)     # (128, 16, 16)\n",
    "        x = self.activation(x)     # (128, 16, 16)\n",
    "\n",
    "        # Stage 5\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Stage 6\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Stage 7\n",
    "        x = self.dense2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Stage 8\n",
    "        x = self.dense3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Stage 9\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "517d5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Plants(len(data_df['label'].unique())).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad88c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]             448\n",
      "         MaxPool2d-2         [-1, 16, 128, 128]               0\n",
      "         LeakyReLU-3         [-1, 16, 128, 128]               0\n",
      "            Conv2d-4         [-1, 32, 128, 128]           4,640\n",
      "         MaxPool2d-5           [-1, 32, 64, 64]               0\n",
      "         LeakyReLU-6           [-1, 32, 64, 64]               0\n",
      "            Conv2d-7           [-1, 64, 64, 64]          18,496\n",
      "         MaxPool2d-8           [-1, 64, 32, 32]               0\n",
      "         LeakyReLU-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10          [-1, 128, 32, 32]          73,856\n",
      "        MaxPool2d-11          [-1, 128, 16, 16]               0\n",
      "        LeakyReLU-12          [-1, 128, 16, 16]               0\n",
      "          Flatten-13                [-1, 32768]               0\n",
      "           Linear-14                  [-1, 256]       8,388,864\n",
      "        LeakyReLU-15                  [-1, 256]               0\n",
      "           Linear-16                  [-1, 128]          32,896\n",
      "        LeakyReLU-17                  [-1, 128]               0\n",
      "           Linear-18                   [-1, 64]           8,256\n",
      "        LeakyReLU-19                   [-1, 64]               0\n",
      "           Linear-20                   [-1, 15]             975\n",
      "================================================================\n",
      "Total params: 8,528,431\n",
      "Trainable params: 8,528,431\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 22.76\n",
      "Params size (MB): 32.53\n",
      "Estimated Total Size (MB): 56.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e541d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=Learning_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38fd1406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [07:36<00:00,  2.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:26<00:00,  4.90it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EPOCHS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 48\u001b[0m\n\u001b[0;32m     44\u001b[0m total_acc_validation_plot\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m((total_acc_val\u001b[38;5;241m/\u001b[39mval_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     46\u001b[0m epoch_finish \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m((time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m epoch_start)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_finish\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_loss_train\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((total_acc_train\u001b[38;5;241m/\u001b[39mtrain_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124m          Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(total_loss_val\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Validation Accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m((total_acc_val\u001b[38;5;241m/\u001b[39mval_data\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124m          \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EPOCHS' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_loss_train_plot = []\n",
    "total_loss_validation_plot = []\n",
    "total_acc_train_plot = []\n",
    "total_acc_validation_plot = []\n",
    "time_plot = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    epoch_start = time.time()\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        train_loss = criterion(outputs, labels)\n",
    "        total_loss_train += train_loss.item()\n",
    "        \n",
    "        train_loss.backward()\n",
    "        train_acc = (torch.argmax(outputs, axis=1) == labels).sum().item()\n",
    "        \n",
    "        total_acc_train += train_acc\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_loss_val += val_loss.item()\n",
    "            \n",
    "            val_acc = (torch.argmax(outputs, axis=1) == labels).sum().item()\n",
    "            total_acc_val += val_acc\n",
    "            \n",
    "    total_loss_train_plot.append(round(total_loss_train/1000, 4))\n",
    "    total_loss_validation_plot.append(round(total_loss_val/1000, 4))\n",
    "    \n",
    "    total_acc_train_plot.append(round((total_acc_train/train_data.__len__()) * 100, 4))\n",
    "    total_acc_validation_plot.append(round((total_acc_val/val_data.__len__()) * 100, 4))\n",
    "      \n",
    "    epoch_finish = round((time.time() - epoch_start)/60, 2)\n",
    "        \n",
    "    print(f'''Epoch {epoch+1}/{Epochs} Time: {epoch_finish} min, Train Loss: {round(total_loss_train/1000, 4)} Train Accuracy: {round((total_acc_train/train_data.__len__()) * 100, 4)}\n",
    "              Validation Loss: {round(total_loss_val/1000, 4)} Validation Accuracy {round((total_acc_val/val_data.__len__()) * 100, 4)}\n",
    "              ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990bb01",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    total_loss_test = 0\n",
    "    total_acc_test = 0\n",
    "    for images, labels in test_loader:\n",
    "        predictions = model(predictions)\n",
    "        \n",
    "        acc = (torch.argmax(predictions, axis=1) == labels).sum().item()\n",
    "        loss = criterion(predictions, labels)\n",
    "        total_loss_test += loss.item()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469815c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
