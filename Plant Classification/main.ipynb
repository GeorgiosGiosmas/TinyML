{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f219a2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\plantdisease\" (use force=True to force download)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets --quiet\n",
    "import opendatasets as od\n",
    "od.download('https://www.kaggle.com/datasets/emmarex/plantdisease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eea67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19824c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b63f0d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 20638\n"
     ]
    }
   ],
   "source": [
    "root_path = 'plantdisease/PlantVillage/'\n",
    "img_path = []\n",
    "labels_path = []\n",
    "\n",
    "for label in os.listdir(root_path):\n",
    "    for item in os.listdir(f'{root_path}/{label}'):\n",
    "        img_path.append(f'{root_path}/{label}/{item}')\n",
    "        labels_path.append(label)\n",
    "        \n",
    "print(f'Number of Images: {len(img_path)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0abad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Tomato__Tomato_YellowLeaf__Curl_Virus          3208\n",
      "Tomato_Bacterial_spot                          2127\n",
      "Tomato_Late_blight                             1909\n",
      "Tomato_Septoria_leaf_spot                      1771\n",
      "Tomato_Spider_mites_Two_spotted_spider_mite    1676\n",
      "Tomato_healthy                                 1591\n",
      "Pepper__bell___healthy                         1478\n",
      "Tomato__Target_Spot                            1404\n",
      "Potato___Early_blight                          1000\n",
      "Potato___Late_blight                           1000\n",
      "Tomato_Early_blight                            1000\n",
      "Pepper__bell___Bacterial_spot                   997\n",
      "Tomato_Leaf_Mold                                952\n",
      "Tomato__Tomato_mosaic_virus                     373\n",
      "Potato___healthy                                152\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plantdisease/PlantVillage//Pepper__bell___Bact...</td>\n",
       "      <td>Pepper__bell___Bacterial_spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path   \n",
       "0  plantdisease/PlantVillage//Pepper__bell___Bact...  \\\n",
       "1  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "2  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "3  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "4  plantdisease/PlantVillage//Pepper__bell___Bact...   \n",
       "\n",
       "                           label  \n",
       "0  Pepper__bell___Bacterial_spot  \n",
       "1  Pepper__bell___Bacterial_spot  \n",
       "2  Pepper__bell___Bacterial_spot  \n",
       "3  Pepper__bell___Bacterial_spot  \n",
       "4  Pepper__bell___Bacterial_spot  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of our Dataframe\n",
    "data_df = pd.DataFrame(zip(img_path, labels_path), columns = ['image_path', 'label'])\n",
    "\n",
    "# Print the distribution of data among classes and the format of our DataFrame.\n",
    "print(data_df['label'].value_counts())\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4cd21e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 16510, Validation size: 2064, Test size: 2064\n"
     ]
    }
   ],
   "source": [
    "train = data_df.sample(frac=0.8)\n",
    "val = data_df.drop(train.index)\n",
    "test = val.sample(frac=0.5)\n",
    "val = val.drop(test.index)\n",
    "\n",
    "print(f'Train size: {len(train)}, Validation size: {len(val)}, Test size: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d692c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder for the Labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(data_df['label'])\n",
    "\n",
    "# Create a transform for transforming the images in the same - appropriate form\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ConvertImageDtype(dtype=torch.float)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88e8a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantsDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.labels = torch.tensor(label_encoder.transform(dataframe['label']), dtype=torch.long).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataframe.shape[0]\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        image = Image.open(self.dataframe.iloc[indx, 0]).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image).to(device)\n",
    "        \n",
    "        label = self.labels[indx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e17d6971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.3333, 0.4431, 0.3961,  ..., 0.4824, 0.4471, 0.3922],\n",
      "         [0.3294, 0.4235, 0.3882,  ..., 0.4353, 0.3608, 0.3569],\n",
      "         [0.3725, 0.4235, 0.3804,  ..., 0.4118, 0.3804, 0.5176],\n",
      "         ...,\n",
      "         [0.6824, 0.6784, 0.7255,  ..., 0.6863, 0.6824, 0.6941],\n",
      "         [0.7176, 0.6824, 0.7176,  ..., 0.7137, 0.7255, 0.7412],\n",
      "         [0.7176, 0.6549, 0.6824,  ..., 0.6863, 0.6980, 0.7137]],\n",
      "\n",
      "        [[0.2745, 0.3843, 0.3373,  ..., 0.4235, 0.3882, 0.3333],\n",
      "         [0.2706, 0.3647, 0.3294,  ..., 0.3765, 0.3020, 0.2980],\n",
      "         [0.3137, 0.3647, 0.3216,  ..., 0.3529, 0.3216, 0.4588],\n",
      "         ...,\n",
      "         [0.6392, 0.6353, 0.6824,  ..., 0.6627, 0.6588, 0.6706],\n",
      "         [0.6745, 0.6392, 0.6745,  ..., 0.6902, 0.7020, 0.7176],\n",
      "         [0.6745, 0.6118, 0.6392,  ..., 0.6627, 0.6745, 0.6902]],\n",
      "\n",
      "        [[0.2863, 0.3961, 0.3490,  ..., 0.4353, 0.4000, 0.3451],\n",
      "         [0.2824, 0.3765, 0.3412,  ..., 0.3882, 0.3137, 0.3098],\n",
      "         [0.3255, 0.3765, 0.3333,  ..., 0.3647, 0.3333, 0.4706],\n",
      "         ...,\n",
      "         [0.6627, 0.6588, 0.7059,  ..., 0.6784, 0.6745, 0.6863],\n",
      "         [0.6980, 0.6627, 0.6980,  ..., 0.7059, 0.7176, 0.7333],\n",
      "         [0.6980, 0.6353, 0.6627,  ..., 0.6784, 0.6902, 0.7059]]]), tensor(10))\n"
     ]
    }
   ],
   "source": [
    "train_data = PlantsDataset(train, transform=transform)\n",
    "val_data = PlantsDataset(val, transform=transform)\n",
    "test_data = PlantsDataset(test, transform=transform)\n",
    "\n",
    "print(val_data.__getitem__(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82fc1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate = 1e-3\n",
    "Batch_Size = 16\n",
    "Epochs = 5\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=Batch_Size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=Batch_Size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=Batch_Size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e2fc1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "class Plants(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv2d1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2d2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv2d3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv2d4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Maxpooling\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Activation Function\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "        # Flatten Layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Dense Layers\n",
    "        self.dense1 = nn.Linear((128*16*16), 256)\n",
    "        self.dense2 = nn.Linear(256, 128)\n",
    "        self.dense3 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, number_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "                                    # x = (3, 256, 256)\n",
    "        # Stage 1\n",
    "        x = self.conv2d1(x)        # (16, 256, 256)\n",
    "        x = self.maxpooling(x)     # (16, 128, 128)\n",
    "        x = self.activation(x)     # (16, 128, 128)\n",
    "        \n",
    "        # Stage 2\n",
    "        x = self.conv2d2(x)        # (32, 128, 128)\n",
    "        x = self.maxpooling(x)     # (32, 64, 64)\n",
    "        x = self.activation(x)     # (32, 64, 64)\n",
    "    \n",
    "        # Stage 3\n",
    "        x = self.conv2d3(x)        # (64, 64, 64)\n",
    "        x = self.maxpooling(x)     # (64, 32, 32)\n",
    "        x = self.activation(x)     # (64, 32, 32)\n",
    "\n",
    "        # Stage 4\n",
    "        x = self.conv2d4(x)        # (128, 32, 32)\n",
    "        x = self.maxpooling(x)     # (128, 16, 16)\n",
    "        x = self.activation(x)     # (128, 16, 16)\n",
    "\n",
    "        # Stage 5\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Stage 6\n",
    "        x = self.dense1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Stage 7\n",
    "        x = self.dense2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Stage 8\n",
    "        x = self.dense3(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Stage 9\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Plants_Small(nn.Module):\n",
    "    \n",
    "    def __init__(self, number_of_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv2d1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2d2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\n",
    "        # Maxpooling\n",
    "        self.maxpooling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Activation Function\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "        # Flatten Layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Dense Layers\n",
    "        self.dense = nn.Linear((32*64*64), 32)\n",
    "        self.output = nn.Linear(32, number_of_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "                                    # x = (3, 256, 256)\n",
    "        # Stage 1\n",
    "        x = self.conv2d1(x)        # (16, 256, 256)\n",
    "        x = self.maxpooling(x)     # (16, 128, 128)\n",
    "        x = self.activation(x)     # (16, 128, 128)\n",
    "        \n",
    "        # Stage 2\n",
    "        x = self.conv2d2(x)        # (32, 128, 128)\n",
    "        x = self.maxpooling(x)     # (32, 64, 64)\n",
    "        x = self.activation(x)     # (32, 64, 64)\n",
    "\n",
    "        # Stage 5\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Stage 6\n",
    "        x = self.dense(x)        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "517d5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  Plants(len(data_df['label'].unique())).to(device)\n",
    "model =  Plants_Small(len(data_df['label'].unique())).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad88c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]             448\n",
      "         MaxPool2d-2         [-1, 16, 128, 128]               0\n",
      "         LeakyReLU-3         [-1, 16, 128, 128]               0\n",
      "            Conv2d-4         [-1, 32, 128, 128]           4,640\n",
      "         MaxPool2d-5           [-1, 32, 64, 64]               0\n",
      "         LeakyReLU-6           [-1, 32, 64, 64]               0\n",
      "           Flatten-7               [-1, 131072]               0\n",
      "            Linear-8                   [-1, 32]       4,194,336\n",
      "            Linear-9                   [-1, 15]             495\n",
      "================================================================\n",
      "Total params: 4,199,919\n",
      "Trainable params: 4,199,919\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 19.00\n",
      "Params size (MB): 16.02\n",
      "Estimated Total Size (MB): 35.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e541d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=Learning_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38fd1406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [04:16<00:00,  4.02it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:19<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 Time: 4.6 min, Train Loss: 2.5241 Train Accuracy: 21.5809\n",
      "              Validation Loss: 0.2758 Validation Accuracy 34.593\n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [04:11<00:00,  4.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:18<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 Time: 4.5 min, Train Loss: 1.8722 Train Accuracy: 44.2944\n",
      "              Validation Loss: 0.1939 Validation Accuracy 55.1357\n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [04:11<00:00,  4.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:18<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 Time: 4.51 min, Train Loss: 1.4694 Train Accuracy: 55.4634\n",
      "              Validation Loss: 0.1668 Validation Accuracy 58.5756\n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [04:11<00:00,  4.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:18<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 Time: 4.5 min, Train Loss: 1.2593 Train Accuracy: 61.7505\n",
      "              Validation Loss: 0.1443 Validation Accuracy 66.4244\n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [04:11<00:00,  4.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:18<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 Time: 4.51 min, Train Loss: 1.1235 Train Accuracy: 65.9055\n",
      "              Validation Loss: 0.1314 Validation Accuracy 67.8295\n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "total_loss_train_plot = []\n",
    "total_loss_validation_plot = []\n",
    "total_acc_train_plot = []\n",
    "total_acc_validation_plot = []\n",
    "time_plot = []\n",
    "\n",
    "for epoch in range(Epochs):\n",
    "    epoch_start = time.time()\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        train_loss = criterion(outputs, labels)\n",
    "        total_loss_train += train_loss.item()\n",
    "        \n",
    "        train_loss.backward()\n",
    "        train_acc = (torch.argmax(outputs, axis=1) == labels).sum().item()\n",
    "        \n",
    "        total_acc_train += train_acc\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            outputs = model(images)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            total_loss_val += val_loss.item()\n",
    "            \n",
    "            val_acc = (torch.argmax(outputs, axis=1) == labels).sum().item()\n",
    "            total_acc_val += val_acc\n",
    "            \n",
    "    total_loss_train_plot.append(round(total_loss_train/1000, 4))\n",
    "    total_loss_validation_plot.append(round(total_loss_val/1000, 4))\n",
    "    \n",
    "    total_acc_train_plot.append(round((total_acc_train/train_data.__len__()) * 100, 4))\n",
    "    total_acc_validation_plot.append(round((total_acc_val/val_data.__len__()) * 100, 4))\n",
    "      \n",
    "    epoch_finish = round((time.time() - epoch_start)/60, 2)\n",
    "        \n",
    "    print(f'''Epoch {epoch+1}/{Epochs} Time: {epoch_finish} min, Train Loss: {round(total_loss_train/1000, 4)} Train Accuracy: {round((total_acc_train/train_data.__len__()) * 100, 4)}\n",
    "              Validation Loss: {round(total_loss_val/1000, 4)} Validation Accuracy {round((total_acc_val/val_data.__len__()) * 100, 4)}\n",
    "              ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "469815c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"plants_model_small.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67e797c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 256, 256]             448\n",
      "         MaxPool2d-2         [-1, 16, 128, 128]               0\n",
      "         LeakyReLU-3         [-1, 16, 128, 128]               0\n",
      "            Conv2d-4         [-1, 32, 128, 128]           4,640\n",
      "         MaxPool2d-5           [-1, 32, 64, 64]               0\n",
      "         LeakyReLU-6           [-1, 32, 64, 64]               0\n",
      "           Flatten-7               [-1, 131072]               0\n",
      "            Linear-8                   [-1, 32]       4,194,336\n",
      "            Linear-9                   [-1, 15]             495\n",
      "================================================================\n",
      "Total params: 4,199,919\n",
      "Trainable params: 4,199,919\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 19.00\n",
      "Params size (MB): 16.02\n",
      "Estimated Total Size (MB): 35.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model =  Plants_Small(len(data_df['label'].unique())).to(device)\n",
    "model.load_state_dict(torch.load(\"plants_model_small.pt\"))\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0a5b37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [00:19<00:00,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1308, Test Accuracy: 68.1686, Inference Time: 0.1089 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation of the trained model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "total_loss_test = 0\n",
    "total_acc_test = 0\n",
    "inference_time = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        \n",
    "        start = time.time()\n",
    "        outputs = model(images)\n",
    "        inference_t = round((time.time() - start), 2)\n",
    "        inference_time.append(inference_t)\n",
    "        \n",
    "        test_loss = criterion(outputs, labels)\n",
    "        total_loss_test += test_loss.item()\n",
    "\n",
    "        test_acc = (torch.argmax(outputs, axis=1) == labels).sum().item()\n",
    "        total_acc_test += test_acc\n",
    "        \n",
    "print(f\"Test Loss: {round(total_loss_test/1000, 4)}, Test Accuracy: {round(total_acc_test/test_data.__len__()*100, 4)}, Inference Time: {round(sum(inference_time)/len(inference_time), 4)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ed81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization and pruning of the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a72e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to tflite mode of the trained model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
